class ForwardShapenetDataset(BaseDataset):
    def __init__(self, dataset_opt):
        super().__init__(dataset_opt)
        forward_category = dataset_opt.forward_category
        if not isinstance(forward_category, str):
            raise ValueError(
                "dataset_opt.forward_category is not set or is not a string. Current value: {}".format(
                    dataset_opt.forward_category
                )
            )
        self._train_categories = dataset_opt.category
        if not is_list(self._train_categories):
            self._train_categories = [self._train_categories]

        # Sets the index of the category with respect to the categories in the trained model
        self._cat_idx = None
        for i, train_category in enumerate(self._train_categories):
            if forward_category.lower() == train_category.lower():
                self._cat_idx = i
                break
        if self._cat_idx is None:
            raise ValueError(
                "Cannot run an inference on category {} with a network trained on {}".format(
                    forward_category, self._train_categories
                )
            )
        log.info(
            "Running an inference on category {} with a network trained on {}".format(
                forward_category, self._train_categories
            )
        )

        self._data_path = dataset_opt.dataroot
        # include_normals = dataset_opt.include_normals if dataset_opt.include_normals else True
        include_normals = dataset_opt.get('include_normals', True)  # Update to OmegaConf 2.0

        transforms = SaveOriginalPosId()
        for t in [self.pre_transform, self.test_transform]:
            if t:
                transforms = T.Compose([transforms, t])
        self.test_dataset = _ForwardShapenet(
            self._data_path, self._cat_idx, transforms=transforms, include_normals=include_normals
        )

    def get_tracker(self, wandb_log: bool, tensorboard_log: bool):
        """Factory method for the tracker
        
        Arguments:
            wandb_log - Log using weight and biases
            tensorboard_log - Log using tensorboard
        Returns:
            [BaseTracker] -- tracker
        """
        return ShapenetPartTracker(self, wandb_log=wandb_log, use_tensorboard=tensorboard_log)

    def predict_original_samples(self, batch, conv_type, output):
        """ Takes the output generated by the NN and upsamples it to the original data
        Arguments:
            batch -- processed batch
            conv_type -- Type of convolutio (DENSE, PARTIAL_DENSE, etc...)
            output -- output predicted by the model
        """
        full_res_results = {}
        num_sample = BaseDataset.get_num_samples(batch, conv_type)
        if conv_type == "DENSE":
            output = output.reshape(num_sample, -1, output.shape[-1])  # [B,N,L]

        setattr(batch, "_pred", output)
        for b in range(num_sample):
            sampleid = batch.sampleid[b]
            sample_raw_pos = self.test_dataset[0].get_raw(sampleid).pos.to(output.device)
            predicted = BaseDataset.get_sample(batch, "_pred", b, conv_type)
            origindid = BaseDataset.get_sample(batch, SaveOriginalPosId.KEY, b, conv_type)
            full_prediction = knn_interpolate(predicted, sample_raw_pos[origindid], sample_raw_pos, k=3)
            labels = full_prediction.max(1)[1].unsqueeze(-1)
            full_res_results[self.test_dataset[0].get_filename(sampleid)] = np.hstack(
                (sample_raw_pos.cpu().numpy(), labels.cpu().numpy(),)
            )
        return full_res_results

    @property
    def class_to_segments(self):
        classes_to_segment = {}
        for key in self._train_categories:
            classes_to_segment[key] = ShapeNet.seg_classes[key]
        return classes_to_segment

    @property
    def num_classes(self):
        segments = self.class_to_segments.values()
        num = 0
        for seg in segments:
            num = max(num, max(seg))
        return num + 1